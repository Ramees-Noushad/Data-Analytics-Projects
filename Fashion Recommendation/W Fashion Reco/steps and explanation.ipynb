{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a1dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f0183b",
   "metadata": {},
   "source": [
    "'numpy' is imported as 'np' for numerical operations.\n",
    "'VGG16' and 'preprocess_input' from Keras are used for the pre-trained VGG16 model and preprocessing images.\n",
    "'image' from Keras is used for image loading and preprocessing.\n",
    "'Model' from Keras is used to create a model based on VGG16.\n",
    "'os' is used for file path manipulations.\n",
    "'pickle' is used to load and save serialized data.\n",
    "'cosine_similarity' from 'sklearn' is used to calculate the similarity between feature vectors.\n",
    "'matplotlib.pyplot' is used for plotting images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24da1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from an image using VGG16\n",
    "def extract_features(img_path, model):\n",
    "    try:\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        features = model.predict(x)\n",
    "        return features.flatten()\n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"Warning: Unable to process image {img_path}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f88b16",
   "metadata": {},
   "source": [
    "'extract_feature's function extracts features from an image.\n",
    "'img_path' is the path to the image, and 'model' is the pre-trained VGG16 model.\n",
    "'image.load_img' loads the image and resizes it to 224x224 pixels.\n",
    "'image.img_to_array' converts the image to a numpy array.\n",
    "'np.expand_dims' adds an extra dimension to match the input shape expected by the model.\n",
    "'preprocess_input' preprocesses the image array to make it suitable for the VGG16 model.\n",
    "'model.predict' extracts the features from the preprocessed image.\n",
    "'features.flatten' converts the features to a one-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb37c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recommend similar dresses based on features\n",
    "def recommend_similar_dresses(query_img_path, features_list, file_names, top_n=5):\n",
    "    # Load pre-trained VGG16 model without the classification layer\n",
    "    base_model = VGG16(weights='imagenet', include_top=False)\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.get_layer('block5_pool').output)\n",
    "    \n",
    "    # Extract features of the query image\n",
    "    query_features = extract_features(query_img_path, model)\n",
    "    \n",
    "    # Compute cosine similarities between the query image and all dataset images\n",
    "    similarities = cosine_similarity([query_features], features_list)\n",
    "    \n",
    "    # Get indices of top similar images\n",
    "    similar_indices = similarities.argsort()[0][-top_n:][::-1]\n",
    "    \n",
    "    # Return top similar images\n",
    "    similar_dresses = [(file_names[i], similarities[0][i]) for i in similar_indices]\n",
    "    return similar_dresses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5721026",
   "metadata": {},
   "source": [
    "'recommend_similar_dresses' function recommends similar dresses based on the query image.\n",
    "'query_img_path' is the path to the query image.\n",
    "'features_list' is the list of feature vectors for the dataset images.\n",
    "'file_names' is the list of image file names in the dataset.\n",
    "'top_n' specifies the number of similar images to return (default is 5).\n",
    "'base_model' loads the pre-trained VGG16 model without the top classification layer.\n",
    "'model' creates a new model that outputs features from the 'block5_pool' layer.\n",
    "'extract_features' extracts features from the query image.\n",
    "'cosine_similarity' computes the cosine similarity between the query image features and the dataset features.\n",
    "'similar_indices' gets the indices of the top similar images, sorted in descending order of similarity.\n",
    "'similar_dresses' pairs the file names with their similarity scores for the top similar images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476cdf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved features and file names\n",
    "features_file = 'dress_features.pkl'\n",
    "with open(features_file, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    features_list = data['features']\n",
    "    file_names = data['file_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e875d0",
   "metadata": {},
   "source": [
    "'features_file' is the path to the saved features file.\n",
    "'pickle.load' loads the serialized data from the file.\n",
    "'features_list' is assigned the list of feature vectors.\n",
    "'file_names' is assigned the list of image file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: recommend similar dresses for a query image\n",
    "query_image_path = r'C:/Users/RAMIZ/Desktop/Wahy/Notes/Project/women_fashion/Anarkali suit with a modern twist.jpg'\n",
    "similar_dresses = recommend_similar_dresses(query_image_path, features_list, file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12444a2d",
   "metadata": {},
   "source": [
    "'query_image_path' is the path to the query image.\n",
    "'recommend_similar_dresses' is called to get the list of similar dresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd408e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print recommended dresses and show the images\n",
    "print('Recommended dresses:')\n",
    "for dress, similarity in similar_dresses:\n",
    "    print(f'Dress: {dress}, Similarity: {similarity:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd8cb8",
   "metadata": {},
   "source": [
    "Prints the file names and similarity scores of the recommended dresses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ffd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the query image and the recommended images\n",
    "def display_images(query_image_path, similar_dresses, dataset_dir):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Show query image\n",
    "    plt.subplot(2, 3, 1)\n",
    "    query_img = image.load_img(query_image_path, target_size=(224, 224))\n",
    "    plt.imshow(query_img)\n",
    "    plt.title(\"Query Image\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Show similar images\n",
    "    for i, (img_name, similarity) in enumerate(similar_dresses):\n",
    "        plt.subplot(2, 3, i+2)\n",
    "        img_path = os.path.join(dataset_dir, img_name)\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Similar: {similarity:.2f}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be052c9a",
   "metadata": {},
   "source": [
    "'display_images' function displays the query image and the recommended similar images.\n",
    "'plt.figure' creates a new figure with the specified size.\n",
    "'plt.subplot(2, 3, 1)' sets up the first subplot (2 rows, 3 columns, position 1) for the query image.\n",
    "'image.load_img' loads the query image.\n",
    "'plt.imshow' displays the query image.\n",
    "'plt.title' sets the title of the query image subplot.\n",
    "'plt.axis('off')' hides the axis for a cleaner display.\n",
    "'for i, (img_name, similarity) in enumerate(similar_dresses)' iterates over the recommended dresses.\n",
    "'plt.subplot(2, 3, i+2)' sets up the next subplot for each recommended image.\n",
    "'os.path.join(dataset_dir, img_name)' constructs the full path to the recommended image.\n",
    "'image.load_img' loads each recommended image.\n",
    "'plt.imshow' displays each recommended image.\n",
    "'plt.title' sets the title of each recommended image subplot with the similarity score.\n",
    "'plt.axis('off')' hides the axis for each recommended image.\n",
    "'plt.show()' displays the figure with all subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ef2172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the dataset images\n",
    "dataset_dir = r'C:\\Users\\RAMIZ\\Desktop\\Wahy\\Notes\\Project\\women_fashion'  # Corrected path\n",
    "\n",
    "display_images(query_image_path, similar_dresses, dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04827bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'dataset_dir' specifies the directory containing the dataset images (replace with the actual path).\n",
    "'display_images' is called to display the query image and the recommended images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e232127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4111b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84005221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65db6b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4404bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2862f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373b5106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363a7bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d2d2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d89f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf09906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd436c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c677332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c5fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3a7c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6495a496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37875927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e8b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
